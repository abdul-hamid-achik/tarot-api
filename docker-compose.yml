services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: development
    image: tarot_api:latest
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    ports:
      - "3000:3000"
    env_file:
      - .env
    environment:
      - RAILS_ENV=development
      - RAILS_MASTER_KEY=${RAILS_MASTER_KEY}
      - S3_ENDPOINT=http://minio:9000
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-minioadmin}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-minioadmin}
      - AWS_BUCKET=${AWS_BUCKET:-tarot-api}
      - AWS_REGION=${AWS_DEFAULT_REGION:-mx-central-1}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      # Database connection settings
      - DB_HOST=postgres
      - DB_NAME=tarot_api_development
      - DB_USERNAME=tarot_api
      - DB_PASSWORD=password
      # PostgreSQL connection pooling and replica setup
      - DB_REPLICA_ENABLED=${ENABLE_REPLICA:-false}
      - DB_PRIMARY_HOST=postgres
      - DB_PRIMARY_PORT=5432
      - DB_PRIMARY_USER=tarot_api
      - DB_PRIMARY_PASSWORD=password
      - DB_REPLICA_HOST=${ENABLE_REPLICA:-false}
      - DB_REPLICA_PORT=${ENABLE_REPLICA:-false}
      - DB_REPLICA_USER=${ENABLE_REPLICA:-false}
      - DB_REPLICA_PASSWORD=${ENABLE_REPLICA:-false}
      # Redis connection pooling and replica setup
      - REDIS_REPLICA_ENABLED=${ENABLE_REPLICA:-false}
      - REDIS_PRIMARY_URL=redis://redis:6379/0
      - REDIS_REPLICA_URL=${ENABLE_REPLICA:-false}
      # Connection pool settings (reduced for dev)
      - DB_POOL_SIZE=5
      - DB_POOL_TIMEOUT=5
      - DB_REAPING_FREQUENCY=10
      - RAILS_MAX_THREADS=3
      - WEB_CONCURRENCY=1
      # Redis connection settings (reduced pools)
      - REDIS_URL=redis://redis:6379/0
      - REDIS_POOL_SIZE=10
      - REDIS_TIMEOUT=2
      # Health check credentials
      - HEALTH_CHECK_USERNAME=admin
      - HEALTH_CHECK_PASSWORD=tarot_health_check
      # Ollama - only included if explicitly enabled
      - OLLAMA_API_HOST=${ENABLE_OLLAMA:-false}
    volumes:
      - gem_cache:/usr/local/bundle
    develop:
      watch:
        - action: sync+restart
          path: ./db/migrate
          target: /app/db/migrate
        - action: sync
          path: .
          target: /app
          ignore:
            - node_modules/
            - .git/
            - tmp/
            - vendor/
            - coverage/
            - log/
            - storage/
            - public/assets/
            - public/packs/
            - .bundle/
            - .docker/
            - .yarn/
            - swagger/
        - action: rebuild
          path: Gemfile
        - action: rebuild
          path: Gemfile.lock
    command: bundle exec rails server -b 0.0.0.0
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    extra_hosts:
      - "host.docker.internal:host-gateway"
      - "localhost:host-gateway"
    networks:
      default:
        aliases:
          - api

  # Ollama is expensive - only enable when needed
  ollama:
    profiles: ["ai"]  # Only starts when explicitly included
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    networks:
      default:
        aliases:
          - ollama

  postgres:
    # Use alpine for smaller footprint
    image: postgres:16-alpine
    volumes:
      - postgres_data:/var/lib/postgresql/data
    env_file:
      - .env
    environment:
      - POSTGRES_PASSWORD=password
      - POSTGRES_USER=tarot_api
      - POSTGRES_DB=tarot_api_development
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
      # Set role parameter for Makara identification
      - POSTGRES_MULTIPLE_DATABASES=false
    command: 
      - "postgres"
      - "-c"
      - "superuser_reserved_connections=0"
      - "-c"
      - "session.role=primary"
      - "-c"
      - "max_connections=50"      # Lower connection count
      - "-c"
      - "shared_buffers=128MB"    # Reduce memory usage
      - "-c"
      - "work_mem=4MB"            # Reduce memory usage
      - "-c" 
      - "maintenance_work_mem=64MB" # Reduce memory usage
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U tarot_api"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    networks:
      default:
        aliases:
          - db
          - postgres
          - localhost

  # Replica is costly - only run when explicitly needed
  # Docker Compose v2 profiles feature to make it optional
  postgres_replica:
    profiles: ["replica"]  # Only starts when explicitly included with --profile replica
    image: postgres:16-alpine
    volumes:
      - postgres_replica_data:/var/lib/postgresql/data
    env_file:
      - .env
    environment:
      - POSTGRES_PASSWORD=password
      - POSTGRES_USER=tarot_api
      - POSTGRES_DB=tarot_api_development
      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256
    command: 
      - "postgres"
      - "-c"
      - "superuser_reserved_connections=0"
      - "-c"
      - "session.role=replica"
      - "-c"
      - "max_connections=50"
      - "-c"
      - "shared_buffers=128MB"
      - "-c"
      - "work_mem=8MB"
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U tarot_api"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    networks:
      default:
        aliases:
          - postgres_replica

  redis:
    # Use alpine for smaller footprint
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    env_file:
      - .env
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    # Optimize Redis for dev (lower memory usage)
    command: >
      redis-server 
      --appendonly yes 
      --maxclients 100 
      --maxmemory 128mb 
      --maxmemory-policy allkeys-lru 
      --save 900 1 
      --save 300 10
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M
    networks:
      default:
        aliases:
          - redis
          - redis-primary
          - localhost

  # Redis replica for read operations
  redis_replica:
    profiles: ["replica"]  # Only starts when explicitly included with --profile replica
    image: redis:7-alpine
    volumes:
      - redis_replica_data:/data
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "6380:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    # Configure as a replica of the master
    command: >
      redis-server
      --replicaof redis 6379
      --maxclients 100
      --maxmemory 128mb
      --maxmemory-policy allkeys-lru
      --replica-read-only yes
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M
    networks:
      default:
        aliases:
          - redis-replica

  minio:
    # Use slim version for smaller footprint
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    env_file:
      - .env
    environment:
      - MINIO_ROOT_USER=${AWS_ACCESS_KEY_ID:-minioadmin}
      - MINIO_ROOT_PASSWORD=${AWS_SECRET_ACCESS_KEY:-minioadmin}
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    networks:
      default:
        aliases:
          - minio

  # Monitoring stack (only starts with --profile monitoring)
  grafana:
    profiles: ["monitoring"]
    image: grafana/grafana:latest
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor
      - GF_UNIFIED_ALERTING_ENABLED=true
    ports:
      - "3001:3000"
    depends_on:
      - loki
      - tempo
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  loki:
    profiles: ["monitoring"]
    image: grafana/loki:latest
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    volumes:
      - loki_data:/loki
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  tempo:
    profiles: ["monitoring"]
    image: grafana/tempo:latest
    command: -config.file=/etc/tempo/tempo-local.yaml
    volumes:
      - tempo_data:/tmp/tempo
    ports:
      - "3200:3200"    # tempo
      - "4317:4317"    # otlp grpc
      - "4318:4318"    # otlp http
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

volumes:
  postgres_data:
  postgres_replica_data:
  redis_data:
  redis_replica_data:
  minio_data:
  gem_cache:
  ollama_data:
  # Monitoring volumes
  grafana_data:
  loki_data:
  tempo_data:

networks:
  default:
    driver: bridge 